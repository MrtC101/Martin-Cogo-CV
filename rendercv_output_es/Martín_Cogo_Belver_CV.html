<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>
        
    </title>
    <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/5.5.1/github-markdown-light.min.css"
        integrity="sha512-Pmhg2i/F7+5+7SsdoUqKeH7UAZoVMYb1sxGOoJ0jWXAEHP0XV2H4CITyK267eHWp2jpj7rtqWNkmEOw1tNyYpg=="
        crossorigin="anonymous" referrerpolicy="no-referrer" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.12/dist/katex.min.css" integrity="sha384-PDbUeNCuE6bOPudPOgFyIUEy3UJawJVwr3XlGO90FIuf5qNIoTLSgOJo/dC2ZXV/" crossorigin="anonymous">

    <!-- The loading of KaTeX is deferred to speed up page rendering -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.12/dist/katex.min.js" integrity="sha384-VkqWq8xtm5YQk1BBXczQ8/Sx+DlCzF8cuS43bZwmtVXzRFtyLTqTCdP7MKmKo+KN" crossorigin="anonymous"></script>

    <!-- To automatically render math in text elements, include the auto-render extension: -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.12/dist/contrib/auto-render.min.js" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous"
        onload="renderMathInElement(document.body, {delimiters: [{ left: '$$',  right: '$$',  display: false }]});"></script>
    <style>
        .markdown-body {
            box-sizing: border-box;
            min-width: 200px;
            max-width: 980px;
            margin: 0 auto;
            padding: 45px;
        }

        @media (max-width: 767px) {
            .markdown-body {
                padding: 15px;
            }
        }
    </style>
</head>

<body>
    <article class="markdown-body">
        <h1>Martín Cogo Belver's CV</h1>
        <ul>
        <li>Phone: +54 9 261 543 7341</li>
        <li>Email: <a href="mailto:martincogo3@gmail.com">martincogo3@gmail.com</a></li>
        <li>Location: Godoy Cruz, Mendoza, Argentina</li>
        <li>Website: <a href="https://mrtc101.github.io/Martin-Cogo-CV/">mrtc101.github.ioMartin-Cogo-CV</a></li>
        <li>LinkedIn: <a href="https://linkedin.com/in/martin-cogo">martin-cogo</a></li>
        <li>GitHub: <a href="https://github.com/MrtC101">MrtC101</a></li>
        </ul>
        <h1>Experiencia Laboral</h1>
        <h2><strong><a href="https://mindcolab.com/">Mind Colab</a></strong>, Computer Science Engineer</h2>
        <p>Jul 2024 – presente</p>
        <p>Desarrollo de un motor de inferencia en tiempo real basado en pipelines de GStreamer, capaz de procesar hasta 6 streams RTSP en paralelo a 720p y 25 FPS, manteniendo frame drop &lt; 1% bajo carga. El sistema adopta una arquitectura multiproceso con IPC mediante memoria compartida, orientada a minimizar copias innecesarias y reducir latencia.</p>
        <ul>
        <li>
        <p><strong>Gestión de flujo</strong>: Manejo de backpressure mediante colas en GStreamer para sostener throughput estable en escenarios de carga concurrente.</p>
        </li>
        <li>
        <p><strong>Stack de aceleración</strong>: Implementación en GPU utilizando NVIDIA DeepStream, buffers NVMM, kernels CUDA (Numba) y OpenCV con soporte CUDA para preprocesamiento.</p>
        </li>
        <li>
        <p><strong>Optimización de inferencia</strong>: Ejecución de modelos YOLO/PyTorch con transferencia de frames mayoritariamente en GPU, reduciendo overhead CPU↔GPU.</p>
        </li>
        <li>
        <p><strong>Lifecycle y operación</strong>: Soporte de restart controlado, hot-reload de configuración mediante DSL propio y graceful shutdown en entornos 24/7.</p>
        </li>
        <li>
        <p><strong>Observabilidad</strong>: Medición de latencia parcial por pipeline y monitoreo de uso de GPU, VRAM, RAM y CPU bajo carga sostenida.</p>
        </li>
        <li>
        <p><strong>Impacto técnico</strong>: Migración desde una solución CPU-bound a GPU, habilitando retransmisión de streams en tiempo real donde previamente no era viable.</p>
        </li>
        </ul>
        <h2><strong><a href="https://www.godoycruz.gob.ar/">Municipalidad de Godoy Cruz</a></strong>, Desarrollador Web</h2>
        <p>Jun 2025 – presente</p>
        <p>Interfaz web para chat con LLM de uso interno para consulta semántica de normativas municipales.</p>
        <ul>
        <li>
        <p><strong>Stack frontend</strong>: React, Tailwind CSS, Bun.</p>
        </li>
        <li>
        <p><a href="https://github.com/AgustinAguilera2323/digesto-semantic-chat">Ver Proyecto</a></p>
        </li>
        </ul>
        <h2><strong><a href="https://klari.ai/">Klari Inc.</a></strong>, Científico de Datos</h2>
        <p>Ene 2025 – Feb 2025</p>
        <p>Diseño e implementación de un sistema de análisis semántico de conversaciones generadas por un chatbot basado en LLM, orientado a extraer patrones temáticos y generar reportes accionables sobre comportamiento y calidad de interacción.</p>
        <ul>
        <li>
        <p><strong>Pipeline NLP</strong>: Representación semántica de conversaciones mediante embeddings.</p>
        </li>
        <li>
        <p><strong>Análisis temático</strong>: Clustering no supervisado para extracción de patrones conversacionales.</p>
        </li>
        </ul>
        <h2><strong><a href="https://sites.google.com/view/cicda/home">Grupo CICDa</a></strong>, Investigación de Tesis</h2>
        <p>Ene 2024 – Ene 2025</p>
        <p>Desarrollo de un trabajo de investigación orientado a publicación, enfocado en la segmentación de imágenes satelitales para la detección y estimación de daños en edificaciones posteriores a desastres naturales, mediante comparación temporal de imágenes y modelos de deep learning con arquitectura siamesa.</p>
        <ul>
        <li>
        <p><strong>Dataset xBD</strong>: Entrenamiento sobre ~2400 imágenes satelitales VHR para tareas de Building Damage Assessment.</p>
        </li>
        <li>
        <p><strong>Pipeline end-to-end</strong>: Preprocesamiento, entrenamiento, inferencia y post-procesamiento para segmentación semántica y detección de cambios estructurales multitemporales.</p>
        </li>
        <li>
        <p><strong>Modelado de visión</strong>: Entrenamiento de modelos de deep learning para segmentación semántica de edificaciones post-desastre.</p>
        </li>
        <li>
        <p><strong>Evaluación experimental</strong>: Análisis cuantitativo mediante métricas de clasificación y segmentación (Precision, Recall, F1-score).</p>
        </li>
        <li>
        <p><strong>Cómputo</strong>: Entrenamiento ejecutado en clúster HPC con GPU NVIDIA Tesla V100.</p>
        </li>
        <li>
        <p><a href="https://github.com/MrtC101/Thesis_DL_for_BDA">Ver Proyecto</a></p>
        </li>
        </ul>
        <h1>Educación</h1>
        <h2><strong>Universidad Nacional de Cuyo</strong>, Licenciatura en Ciencias de la Computación</h2>
        <p>2020 – 2024</p>
        <h1>Habilidades Técnicas</h1>
        <p><strong>Lenguajes:</strong> Python, JavaScript, C/C++</p>
        <p><strong>IA &amp; ML:</strong> PyTorch, TensorFlow, Scikit-learn</p>
        <p><strong>Visión &amp; Datos:</strong> OpenCV, CUDA, Gstreamer, NVIDIA DeepStream, Pandas, NumPy</p>
        <p><strong>Herramientas:</strong> Docker, Linux, Git, FastAPI, Bun, React, Tailwind</p>
        <h1>Logros Y Idiomas</h1>
        <ul>
        <li>
        <p>Medalla a mejor promedio promocion 2024 de la carrera Licenciatura en ciencias de la computación.</p>
        </li>
        <li>
        <p>Cuadro de honor (Top 15 promedios): Facultad de Ingeniería UNCUYO, 2024.</p>
        </li>
        <li>
        <p>Inglés: Nivel B2 (Certificado por Cambridge).</p>
        </li>
        </ul>
    </article>
</body>

</html>